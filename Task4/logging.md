# Архитектурное решение по логированию

Собирать логи нужно со всех `API`, настроить это можно даже для `MES API`, хоть исходный код и был приобретен.
Также можно добавить сбор логов с `RabbitMQ`, чтобы отслеживать события по заказам.

На уровне `INFO` будем в первую очередь собирать следующие логи:
* **изменение статуса заказа** (во всех трех `API`) -- логируем время, id заказа, id пользователя, обновленный статус
* **начало загрузки 3d файла** (`Shop API`) -- логируем время, id заказа и пользователя, путь файла в `S3`
* **окончание загрузки 3d файла** (`Shop API`), если оно синхронное -- логируем все то же самое
* **добавление/редактирование товаров** (`CRM API`) -- логируем время, id продавца (Seller), id товара
* **назначение заказа на оператора** (`MES API`) -- логируем время, id заказа, id оператора

Дополнительно, хорошо бы собирать расширенные логи с уровнем `DEBUG`, которые будут храниться меньше по времени,
но дадут больше понимания по работе системы:
* **все запросы в API** (особенно изменяющие) -- логируем время, http-путь с параметрами, хост приложения,
HTTP-метод, по возможности код ответа
* **события из RabbitMQ** -- информацию о добавлении новых ивентов и их acknoledgement'е на хостах

А еще, в случае ошибок в коде приложения (неожиданных ситуаций и тд), будет полезно логировать такое с уровнем
`ERROR`, чтобы понимать причины падения запросов.

## Мотивация

Для логирования мотивация очень схожа с трейсингом. Внедрение поможет расследовать потерявшиеся заказы, зависшие
в определенных статусах. В будущем это поможет повысить уровень удовлетворенности клиентов интернет-магазина и их
retention. Также своевременный фикс выявленных недостатков поможет повысить пользовательский опыт и продавать
больше изделий, повышая GMV и прочее.

С технической точки зрения, правильная настройка логирования упрощает его использование разработчиками и позволяет
проверять новую функциональность, расследовать инциденты и прочее. Даже если начать писать логи, но не собирать
их в единое хранилище, разработчики будут вынуждены в процессе расследования подключаться к каждому сервису
по отдельности и искать логи по текстовым файлам...

Настройка алертов на кол-во логов или на сообщения определенного уровня (`ERROR` и выше) поможет отслеживать
работоспособность системы и отлавливать ошибки еще до того, как клиенты могут их обнаружить. Все это значительно
повышает пользовательский опыт.

## Предлагаемое решение

Для логирование предлагается использовать `ELK`-стек, тем более что данные трейсинга тоже собираются в
`Elasticsearch`. Для сбора логов `RabbitMQ` скорее всего нужен будет специальный `Beat`, он уже реализован.

С точки зрения безопасности, `Kibana` можно будет скрыть от всех, кроме команды разработчиков, все тем же прокси,
который настраивался для трейсинга. `Jaeger UI auth proxy` будет выполнять авторизацию и ограничивать доступ только
для пользователей с ролью `admin`/`maintainer`.

В первую очередь необходимо настроить логирование для `MES API` и `Shop API`, так как там происходит бОльшая часть
изменений статусов заказа, с которыми уже сейчас наблюдаются значительные проблемы. Это поможет как можно раньше
начать диагностировать существующие баги в системе и устранять их.

Далее, можно будет добавить сбор логов с `CRM API` и `RabbitMQ`, потому как эти логи менее значимы. Все эти связи отражены на диаграмме.

Индексы предлагается создавать по датам, по одному для каждого дня. Это позволит держать небольшие размеры,
а также разделять индексы на `hot`/`warm`, т.к. чаще всего нужен поиск по недавним логам. Также это упрощает
их удаление, можно удалять индексы целиком, что улучшает производительность.

Дополнительно, стоит поставить ограничение на размер индекса, чтобы разделять его на несколько при достижении
определенной границы. Порог можно выставить на 20-30 Гб, а затем посмотреть, что из этого выходит на практике,
сколько индексов в день собирает система и тд, после чего при необходимости уточнять границу.

Также, может пригодиться выделение отдельных индексов для некоторых систем (например, `RabbitMQ`), в которых
может быть много данных, но запросы на них выполняются редко.

Срок хранения для основных `INFO` и `ERROR` логов можно выставить в 1 месяц на быстром хранилище, а потом
перемещать на медленное (HDD) и хранить там в течение 6-12 месяцев для будущей диагностики.
`DEBUG`-логи вообще можно хранить в течение нескольких дней - недели, т.к. их будет слишком много на таком подробном
уровне логирования.

[Ссылка на просмотр обновленной диаграммы](https://drive.google.com/file/d/17UjCHrZ6oPP-gnEvyNsxHOJy00Y-SjLt/view?usp=sharing), исходный DrawIO файл в текущей директории.

## Анализ логов, алертинг

В кибане хорошо бы настроить базовый алертинг, есть такие варианты:
* **кол-во ERROR логов** - отслеживать массовые ошибки, которые могут сигнализировать о недоступности сервисов
или плохом релизе
* **кол-во логов с определенного сервиса** - в первую очередь для API, так как на уровне `DEBUG` там будут
логироваться все запросы. Это может быть показателем всплеска нагрузки, может даже атаки на сервис (DDoS и тд)
